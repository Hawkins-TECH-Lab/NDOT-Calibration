{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "469e7867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dbfread import DBF\n",
    "\n",
    "# Reading the Counts CSV file into df1\n",
    "df1 = pd.read_csv('final_vcount.csv')\n",
    "\n",
    "# Reading the DBF file into df2\n",
    "dbf_table = DBF('Veh_Network_StL_Calibration_v1.5.dbf')\n",
    "df2 = pd.DataFrame(iter(dbf_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d874ee57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N 33rd St & North Star_2019.xlsm', 'N 48th St & Target_2019.xlsm', 'S 14th St & YMCA_2020.xlsm', 'N Antelope Valley Pkwy & Military Rd_2019.xlsm', 'N Cotner Blvd & Vine St_2020.xlsm', 'S 70th St & Pine Lake Rd_2017.xlsx', 'N 48th St & Cornhusker Hwy _2022.xlsm', 'N 48th St & Cornhusker Hwy_2019.xlsm', 'NW 48th St & I80 WB_2017.xlsx', 'W 40th St & W O St_2018.xlsm', 'W 40th St & W O St_2018.xlsx', 'W 40th St & W O St_2022.xlsm', '56th St & O St_2019.xlsm', '56th St & O St_2022.xlsm', 'Capitol Pkwy & J St_2017.xlsx', 'S 33rd St & Hwy 2 _2017.xlsx', 'S 48th St & Normal Blvd_2019.xlsm', 'N 12th St & Q St_2017.xlsx', 'N 16th St & W St_2017.xlsx', 'N Antelope Valley Pkwy & Salt Creek Rdwy_2020.xlsm', 'N Antelope Valley Pkwy & Salt Creek Rdwy_2022.xlsm', 'Cotner Blvd & O St_2017.xlsx', 'N 48th St & Huntington Ave Ped Nov_2017.xlsm', 'N 48th St & Huntington Ave Ped Nov_2019.xlsm', 'N 48th St & Huntington Ave Ped Oct_2019.xlsm', 'S 13th St & Arapahoe St_2017.xlsx', 'S 13th St & Arapahoe St_2020.xlsm', 'N 17th St & R St_2017.xlsx', 'N 16th St & Vine St_2017.xlsx', 'N 16th St & Vine St_2018.xlsx', 'N 16th St & Vine St_Oct2017.xlsx', 'N 16th St & Vine St_Sept2017.xlsx', 'S 40th St & Yankee Hill Rd_2018.xlsx', 'S 91st St & Hwy 2_2017.xlsx', 'S 91st St & Hwy2_2020.xlsm', 'S 14th St & Pine Lake Rd_2018.xlsx', 'S 56th St & Pine Lake Rd_2018.xlsx', 'S 37th St & Sheridan Blvd Ped_2017.xlsm', 'Antelope Valley Pkwy & O St_2020.xlsm', 'N 14th St & Salt Creek Rdwy_2020.xlsm', 'N 84th St & Adams St_2017.xlsx', 'NW 48th St & W Adams St_2017.xlsx', 'NW 48th St & W Adams St_2020.xlsm', 'Cornhusker Hwy & Superior St-Havelock Ave_2018.xlsx', 'N Antelope Valley Pkwy & Vine St_2018.xlsm', 'N Antelope Valley Pkwy & Vine St_2018.xlsx', 'N Antelope Valley Pkwy & Vine St_2022.xlsm', 'S 70th St & Pioneers Blvd_2019.xlsm', 'S Antelope Valley & N St_2019.xlsm', 'S 84th & Hwy 2_2017.xlsx', 'S 84th St & Hwy 2_2020.xlsm', 'S 56th St & Old Cheney Rd_2018.xlsx', 'S 27th St & Capitol Pkwy_2018.xlsx', 'S 27th St & Grainger Pkwy_2018.xlsx', 'S 14th St-S 13th St & Hwy 2_2018.xlsm', 'Hwy 2 & Pioneers Blvd_2019.xlsm', 'Hwy 2 & Pioneers Blvd_2022.xlsm', '70th St & O St_2017.xlsx', '66th St & O St_2018.xlsm', 'Lyncrest Dr & O St_2019.xlsm', 'Lyncrest Dr & O St_2022.xlsm', 'Sun Valley Blvd & Westgate Blvd_2019.xlsm', 'NW 48th St & I80 EB_2017.xlsx', 'N 27th St & Fair St_2019.xlsm', 'N 84th St & Windmill Dr_2017.xlsx', 'N 84th St & Windmill Dr_2018.xlsm', 'N 20th St & Cornhusker Hwy_2019.xlsm', 'N 20th St & Cornhusker Hwy_2022.xlsm', 'Touzalin Ave & Fremont St_2018.xlsm', 'Touzalin Ave & Fremont St_2022.xlsm', 'Touzalin Ave & Havelock Ave_2019.xlsm', 'NW 1st St & W Fletcher Ave_2019.xlsm', 'N 84th St & Cornhusker Hwy_2016.xlsx', 'N 84th St & Cornhusker Hwy_2019.xlsm', 'Capitol Pkwy & Randolph St_2019.xlsm', '10th St & O St_2015-NHW154-LT01.xlsx', '10th St & O St_2015.xlsx', '10th St & O St_2019.xlsm', '11th St & O St_2016.xlsx', '11th St & O St_2019.xlsm', '12th St & O St_2017.xlsx', '13th St & O St_2019.xlsm', '14th St & O St_2017.xlsx', '16th St & O St_2018.xlsm', '17th St & O St_2018.xlsm', '25th St & O St_2019.xlsm', '25th St & O St_2022.xlsm', '27th St & O St_2019.xlsm', '27th St & O St_2022.xlsm', 'N 33rd St & Holdrege St_2018.xlsm', '33rd St & O St_2019.xlsm', '44th St & O St_2016.xlsx', '44th St & O St_2019.xlsm', '48th St & O St_2018.xlsx', '52nd St & O St_2019.xlsm', '63rd St & O St_2019.xlsm', '63rd St & O St_2022.xlsm', '68th St & O St_2019.xlsm', '84th St & O St_2020.xlsm', '90th St & O St_2018.xlsm', '90th St & O St_2018_updatedtemplate.xlsm', '90th St & O St_2019 - EBL vs WBT.xlsm', '90th St & O St_2019.xlsm', '98th St & O St_2017.xlsx', '98th St & O St_2018.xlsm', '9th St & O St_2015.xlsx', '9th St & O St_2019.xlsm', 'Capitol Beach Blvd & W O St_2022.xlsm', 'Capitol Beach Blvd & West O St_2020.xlsm', 'Capitol Pkwy & A St - doesnt include S. 32nd St_2018.xlsm', 'Centennial Mall & M St_2019.xlsm', 'Centennial Mall & N St_2019.xlsm', 'Centennial Mall & O St_2019-NHW154-LT01.xlsm', 'Centennial Mall & O St_2019.xlsm', 'Centennial Mall & P St_2019.xlsm', 'Colony Ln & Vine St Ped_2017.xlsm', 'Cottonwood Dr & A St Ped_2017.xlsm', 'Dairy Store Dr & Holdrege St_2019.xlsm', 'I180 NB & Superior St_2019.xlsm', 'I180 NB & Superior St_2022.xlsm', 'I180 SB & Superior St_2019.xlsm', 'I180 SB & Superior St_2022.xlsm', 'Industrial Ave & Superior St_2019.xlsm', 'Industrial Ave & Superior St_2022.xlsm', 'Lucile Dr & Pioneers Blvd_2020.xlsm', 'Lucille Dr & Pioneers Blvd_2016.xlsx', 'N 10th St & Charleston St_2018.xlsm', 'N 10th St & Charleston St_2022.xlsm', 'N 10th St & P St_2019.xlsm', 'N 10th St & Q St_2019.xlsm', 'N 11th St & Cornhusker Hwy_2019.xlsm', 'N 11th St & Cornhusker Hwy_2022.xlsm', 'N 11th St & P St_2019.xlsm', 'N 11th St & Q St_2017.xlsx', 'N 11th St & Saunders Ave_2019.xlsm', 'N 11th St & Saunders Ave_2022.xlsm', 'N 12th St & P St_2019.xlsm', 'N 13th St & P St_2019.xlsm', 'N 13th St & Q St_2019.xlsm', 'N 14th St & Adams St_2018.xlsm', 'N 14th St & Adams St_2022.xlsm', 'N 14th St & Fletcher Ave-Turtle Creek Rd_2018.xlsm', 'N 14th St & Fletcher Ave_2018.xlsm', 'N 14th St & Humphrey Ave_2017.xlsm', 'N 14th St & Humphrey Ave_2017.xlsx', 'N 14th St & P St_2019.xlsm', 'N 14th St & Q St_2017.xlsx', 'N 14th St & Saunders Ave_2022.xlsm', 'N 14th St & Vine St_2018.xlsm', 'N 14th St & Yolande Ave_2022.xlsm', 'N 16th St & P St_2018.xlsm', 'N 16th St & Q St_2018.xlsm', 'N 16th St & R St_2017.xlsx', 'N 16th St & R St_2018.xlsx', 'N 16th St & S St_2017.xlsx', 'N 16th St & S St_2018.xlsx', 'N 17th St & P St_2018.xlsm', 'N 17th St & Q St_2018.xlsm', 'N 17th St & Vine St_2018.xlsm', 'N 1st St & Cornhusker Hwy_2018.xlsx', 'N 1st St & Superior St_2017.xlsx', 'N 20th St & Superior St_2019.xlsm', 'N 20th St & Superior St_2022.xlsm', 'N 22nd St & Y St_2018.xlsm', 'N 27th St & Cornhusker Hw_2019.xlsm', 'N 27th St & Cornhusker Hwy_2017.xlsx', 'N 27th St & Cornhusker Hwy_2020.xlsm', 'N 27th St & Fairfield St_2018.xlsm', 'N 27th St & Fletcher Ave_2019.xlsm', 'N 27th St & Folkways Blvd_2019.xlsm', 'N 27th St & Folkways Blvd_2022.xlsm', 'N 27th St & Holdrege St_2018.xlsm', 'N 27th St & Kensington Dr_2019.xlsm', 'N 27th St & Kensington Dr_2022.xlsm', 'N 27th St & Knox St_2019.xlsm', 'N 27th St & Old Dairy Dr_2022.xlsm', 'N 27th St & Old Dairy Rd_2019.xlsm', 'N 27th St & P St_2018.xlsm', 'N 27th St & Superior St_2018.xlsx', 'N 27th St & Superior St_2020.xlsm', 'N 27th St & Theresa St_2019.xlsm', 'N 27th St & Ticonderoga Dr_2018.xlsm', 'N 27th St & Vine St_2017.xlsx', 'N 27th St & Vine St_2020.xlsm', 'N 27th St & Whitehead Dr_2019.xlsm', 'N 27th St & Whitehead Dr_2022.xlsm', 'N 27th St & Y St_2019.xlsm', 'N 29th St-State Fair Park Dr & Cornhusker Hwy_2019.xlsm', 'N 29th St-State Fair Park Dr & Cornhusker Hwy_2022.xlsm', 'N 31st St & Vine St_2018.xlsm', 'N 33rd St & Cornhusker Hwy_2017.xlsx', 'N 33rd St & Cornhusker Hwy_2019.xlsm', 'N 33rd St & Huntington Ave_2019.xlsm', 'N 33rd St & Superior St_2018.xlsx', 'N 33rd St & Vine St_2019.xlsm', 'N 35th St Adams St & Cornhusker Hwy_2022.xlsm', 'N 35th St-Adams St & Cornhusker Hwy_2019.xlsm', 'N 40th St & Cornhusker Hwy_2019.xlsm', 'N 40th St & Superior St_2017.xlsx', 'N 40th St & Superior St_2022.xlsm', 'N 44th St & Cornhusker Hwy_2018.xlsx', 'N 45th St & Vine St_2019.xlsm', 'N 46th St & R St_2019.xlsm', 'N 48th St & Adams St_2018.xlsx', 'N 48th St & Baldwin Ave_2019.xlsm', 'N 48th St & Fremont St_2018.xlsx', 'N 48th St & Holdrege St_2017.xlsx', 'N 48th St & Holdrege St_2019.xlsm', 'N 48th St & Leighton Ave_2019.xlsm', 'N 48th St & Leighton Ave_2022.xlsm', 'N 48th St & Madison Ave_2019.xlsm', 'N 48th St & R St_2018.xlsx', 'N 48th St & St Paul Ave_2018.xlsx', 'N 48th St & Superior St_2017.xlsx', 'N 48th St & Vine St_2017.xlsx', 'N 52nd St & R St_2020.xlsm', 'N 52nd St & R St_2022.xlsm', 'N 56th St & Adams St_2018.xlsx', 'N 56th St & Arbor Rd_2017.xlsx', 'N 56th St & Fremont St_2018.xlsm', 'N 56th St & Holdrege St_2019.xlsm', 'N 56th St & Holdrege St_No Peds Apr 2019.xlsm', 'N 56th St & Leighton Ave_2018.xlsm', 'N 56th St & R St_2018.xlsm', 'N 56th St & Vine St_2017.xlsx', 'N 62nd St & Havelock Ave_2019.xlsm', 'N 62nd St & Havelock Ave_2022.xlsm', 'N 63rd St & Adams St_2020.xlsm', 'N 66th St & Adams St & Cotner Blvd_2018.xlsx', 'N 66th St N Cotner Blvd & Adams St_2022.xlsm', 'N 66th St & Q St_2017.xlsx', 'N 66th St & Q St_2020.xlsm', 'N 66th St & Starr St & Cotner Blvd_2020.xlsm', 'N 66th St & Vine St_2019.xlsm', 'N 70th St & Fremont St_2019.xlsm', 'N 70th St & Havelock Ave_2018.xlsx', 'N 70th St & Huntington Ave Ped Nov_2017.xlsm', 'N 70th St & Huntington Ave Ped_2019.xlsm', 'N 70th St & Leighton Ave_2018.xlsx', 'N 70th St & Vine St_2018.xlsx', 'N 84th St & College Park Dr_2019.xlsm', 'N 84th St & Fremont St_2019.xlsm', 'N 84th St & Havelock_2017.xlsx', 'N 84th St & Holdrege St_2017.xlsx', 'N 84th St & Vine St_2018.xlsm', 'N 8th St & P St_2019.xlsm', 'N 9th St & P St_2019.xlsm', 'N 9th St & Q St_2017.xlsx', 'N Antelope Valley Pkwy & N 17th St_2019.xlsm', 'N Antelope Valley Pkwy & N 17th St_2022.xlsm', 'N Antelope Valley Pkwy & P St_2018.xlsm', 'N Antelope Valley Pkwy & Q St_2018.xlsm', 'N Cotner Blvd & Holdrege St_2019.xlsm', 'N Cotner Blvd & Leighton Ave_2017.xlsx', 'N Cotner Blvd & Leighton Ave_2020.xlsm', 'N Cotner Blvd & R St_2019.xlsm', 'N Cotner Blvd & R St_2022.xlsm', 'Normal Blvd & South St_2019.xlsm', 'Normal Blvd & South St_2022.xlsm', 'Normal Blvd & Sumner St_2018.xlsm', 'NW 12th St & W Adams St_2018.xlsm', 'NW 12th St & W Cornhusker Hwy_2019.xlsm', 'NW 12th St & W Highland Blvd_2017.xlsx', 'NW 48th St & W Gately St_2019.xlsm', 'NW 48th St & W Huntington Ave_2017.xlsx', 'NW 48th St & W Huntington Ave_2020.xlsm', 'NW 48th St & W Knight Dr Ped_2017.xlsm', 'NW 48th St & W Knight Dr Ped_2022.xlsm', 'NW 48th St & W O St_2017.xlsx', 'NW 48th St & W Superior St_2019.xlsm', 'NW 4th St & W Cornhusker Hwy_2019.xlsm', 'NW 4th St & W Cornhusker Hwy_No Peds Apr 2019.xlsm', 'NW 7th St & W Fletcher Ave Ped_2017.xlsm', 'Park Blvd & Van Dorn St_2019.xlsm', 'Pine Lake Rd-Ashbrook Dr & Hwy 2_2017.xlsx', 'Pine Lake Rd-Ashbrook Dr & Hwy 2_2020_09_15.xlsm', 'Pine Lake Rd-Ashbrook Dr & Hwy 2_2020_09_16.xlsm', 'Ridge Rd-Helen Witt Dr & Pine Lake Rd_2018.xlsx', 'Roundhouse St & West O St_2020.xlsm', 'S 10th St & A St_2019.xlsm', 'S 10th St & D St_2019.xlsm', 'S 10th St & G St_2019.xlsm', 'S 10th St & K St_2019.xlsm', 'S 10th St & L St_2019.xlsm', 'S 10th St & Lincoln Mall_2019.xlsm', 'S 10th St & M St_2019.xlsm', 'S 10th St & N St_2019.xlsm', 'S 10th St & South St_2019.xlsm', 'S 10th St & Van Dorn St_2019.xlsm', 'S 11th St & K St_2019.xlsm', 'S 11th St & L St_2019.xlsm', 'S 11th St & M St_2017.xlsx', 'S 11th St & N St_2017.xlsx', 'S 12th St & K St_2019.xlsm', 'S 12th St & L St_2019.xlsm', 'S 12th St & M St_2017.xlsx', 'S 12th St & N St_2019.xlsm', 'S 13th St & A St_2018.xlsx', 'S 13th St & G St_2018.xlsx', 'S 13th St & K St_2019.xlsm', 'S 13th St & L St_2017.xlsx', 'S 13th St & M St_2017.xlsx', 'S 13th St & N St_2017.xlsx', 'S 13th St & South St_2018.xlsx', 'S 13th St & Van Dorn St_2017.xlsx', 'S 13th St & Van Dorn St_2020.xlsm', 'S 14th St & Aberdeen Ave-Old Farm Rd_2017.xlsx', 'S 14th St & Aberdeen Ave-Old Farm Rd_2020.xlsm', 'S 14th St & Garret Ln_2018.xlsx', 'S 14th St & Infinity Ct_2018.xlsm', 'S 14th St & Infinity Ct_2018.xlsx', 'S 14th St & K St_2018.xlsm', 'S 14th St & L St_2019.xlsm', 'S 14th St & M St_2017.xlsx', 'S 14th St & N St_2017.xlsx', 'S 14th St & Old Cheney Rd_2019.xlsm', 'S 16th St & A St_2018.xlsm', 'S 16th St & D St_2017.xlsx', 'S 16th St & G St_2019.xlsm', 'S 16th St & J St Ped Nov_2017.xlsm', 'S 16th St & K St_2017.xlsx', 'S 16th St & L St_2017.xlsx', 'S 16th St & M St_2019.xlsm', 'S 16th St & N St_2017.xlsx', 'S 16th St & Old Cheney Rd_2019.xlsm', 'S 16th St & South St_2019.xlsm', 'S 17th St & A St_2019.xlsm', 'S 17th St & D St_2017.xlsx', 'S 17th St & G St_2019.xlsm', 'S 17th St & J St Ped_2017.xlsm', 'S 17th St & K St_2017.xlsx', 'S 17th St & L St_2017.xlsx', 'S 17th St & Lake St Ped Oct_2017.xlsm', 'S 17th St & M St_2017.xlsx', 'S 17th St & N St_2019.xlsm', 'S 17th St & South St_2018.xlsx', 'S 17th St & Van Dorn St_2017.xlsx', 'S 17th St & Van Dorn St_2020.xlsm', 'S 17th St & Washington St_2017.xlsm', 'S 17th St & Washington St_2017.xlsx', 'S 17th St & Washington St_2019.xlsm', 'S 20th St & A St Ped Nov_2017.xlsm', 'S 20th St & A St Ped_2019.xlsm', 'S 20th St-Hazel Scott Dr & Pine Lake Rd_2018.xlsx', 'S 20th St & South St Ped_2017.xlsm', 'S 21st St & K St_2019.xlsm', 'S 21st St & K St_2022.xlsm', 'S 21st St & L St_2019.xlsm', 'S 21st St & L St_2022.xlsm', 'S 26th St & South St Sunday_2018.xlsm', 'S 26th St & South St_2018.xlsm', 'S 27th St & A St_2018.xlsx', 'S 27th St & Hwy 2_2017.xlsx', 'S 27th St & J St_2019.xlsm', 'S 27th St & Jameson N_2019.xlsm', 'S 27th St & Jameson N_2022.xlsm', 'S 27th St & Old Cheney Rd_2018.xlsx', 'S 27th St & Pine Lake Rd_2018.xlsx', 'S 27th St & Porter Ridge Rd_2019.xlsm', 'S 27th St & Randolph St_2019.xlsm', 'S 27th St & Ridge Rd-Laredo Dr_2022.xlsm', 'S 27th St & Sheridan Blvd_2017.xlsx', 'S 27th St & South St_2017.xlsx', 'S 27th St & Southridge Rd_2019.xlsm', 'S 27th St & Sumner St Ped Nov_2017.xlsm', 'S 27th St & Sumner St Ped_2019.xlsm', 'S 27th St & Tamarin Ridge Rd_2017.xlsx', 'S 27th St & Tipperary Tr_2022.xlsm', 'S 27th St & Tipperary Trl_2019.xlsm', 'S 27th St & Van Dorn St_2018.xlsm', 'S 27th St & Woods Blvd_2019.xlsm', 'S 27th St & Yankee Hill Rd_2017.xlsx', 'S 33rd & Yankee Hill Rd_2017.xlsx', 'S 33rd St & A St_2018.xlsx', 'S 33rd St & D St_2017.xlsx', 'S 33rd St & D St_2020.xlsm', 'S 33rd St & J St_2019.xlsm', 'S 33rd St & Pioneers Blvd_2019.xlsm', 'S 33rd St & Randolph St_2019.xlsm', 'S 33rd St & South St_2017.xlsx', 'S 34th St & Old Cheney Rd_2019.xlsm', 'S 34th St & Old Cheney Rd_2022.xlsm', 'S 37th St & A St Ped Nov_2017.xlsm', 'S 37th St & A St Ped_2019.xlsm', 'S 40th St & A St_2018.xlsx', 'S 40th St & D St_2017.xlsx', 'S 40th St & Duxhall Dr_2019.xlsm', 'S 40th St & Grainger Pkwy_2019.xlsm', 'S 40th St & Hwy 2_2018.xlsm', 'S 40th St & Normal Blvd_2019.xlsm', 'S 40th St & Normal Blvd_2022.xlsm', 'S 40th St & Old Cheney Rd_2018.xlsx', 'S 40th St & Pine Lake Rd_2018.xlsx', 'S 40th St & Pioneers Blvd_2018.xlsm', 'S 40th St & Randolph St_2018.xlsm', 'S 40th St & South St_2018.xlsx', 'S 40th St & Van Dorn St_2018.xlsm', 'S 40th St & Wildbriar Lane_2019.xlsm', 'S 48th & S Cotner Blvd_2022.xlsm', 'S 48th St & Cotner Blvd_2018.xlsx', 'S 48th St & A St_2019.xlsm', 'S 48th St & A St_2022.xlsm', 'S 48th St & Calvert St_2019.xlsm', 'S 48th St & Calvert St_2022.xlsm', 'S 48th St & Hwy 2_2019.xlsm', 'S 48th St & Old Cheney Rd_2019.xlsm', 'S 48th St & Old Cheney Rd_2022.xlsm', 'S 48th St & Pioneers Blvd_2019.xlsm', 'S 48th St & Pioneers Blvd_2022.xlsm', 'S 48th St & Prescott Ave_2019.xlsm', 'S 48th St & Prescott Ave_2022.xlsm', 'S 48th St & Prescott Ave_No Peds Mar 2019.xlsm', 'S 48th St & Randolph St_2019.xlsm', 'S 48th St & Randolph St_2022.xlsm', 'S 48th St & Randoph St_2019.xlsm', 'S 48th St & South St_2018.xlsx', 'S 48th St & South St_2022.xlsm', 'S 48th St & Sumner St_2019.xlsm', 'S 48th St & Sumner St_2022.xlsm', 'S 48th St & Van Dorn St_2018.xlsx', 'S 48th St & Van Dorn St_2022.xlsm', 'S 50th St & Cotner Blvd & A St_341748_09-08-2016_legVolsCalc.xlsx', 'S Cotner Blvd & A St Does not include 50th St Leg_2019.xlsm', 'S Cotner Blvd & A St Does not include 50th St Leg_2022.xlsm', 'S 51st St & Van Dorn St_2016.xlsx', 'S 51st St & Van Dorn St_2019.xlsm', 'S 51st St & Van Dorn St_2022.xlsm', 'S 52nd St & A St Ped Nov_2017.xlsm', 'S 52nd St & A St Ped_2019.xlsm', 'S 52nd St & Normal Blvd Ped_2017.xlsm', 'S 56th St & A St_2018.xlsx', 'S 56th St & A St_2022.xlsm', 'S 56th St & Elkcrest Dr_2018.xlsx', 'S 56th St & Hwy 2 _2016.xlsx', 'S 56th St & Normal Blvd_2017.xlsx', 'S 56th St & Pioneers Blvd_2018.xlsx', 'S 56th St & Randolph St & Cotner Blvd_214299_03-02-2015_LegVolsCalc.xlsx', 'S 56th St & Randolph St & Cotner Blvd_518777_04-30-2018_LegVolsCalc.xlsx', 'S 56th St & South St_2018.xlsx', 'S 56th St & South St_2022.xlsm', 'S 56th St & Sunrise Rd Ped_2017.xlsm', 'S 56th St & Sunrise Rd Ped_2019.xlsm', 'S 56th St & Van Dorn St_2018.xlsx', 'S 56th St & Waltz Rd_2019.xlsm', 'S 56th St & Waltz Rd_2022.xlsm', 'S 70th St & A St_2018.xlsx', 'S 70th St & Glynoaks Dr_2016.xlsx', 'S 70th St & Glynoaks Dr_2019.xlsm', 'S 70th St & Holmes Park Rd Oct29_2019.xlsm', 'S 70th St & Holmes Park Rd Oct30_2019.xlsm', 'S 70th St & Hwy 2_2017.xlsx', 'S 70th St & L St_2019.xlsm', 'S 70th St & Old Cheney Rd_2018.xlsx', 'S 70th St & South St_2019.xlsm', 'S 70th St & Stacy Ln_2019.xlsm', 'S 70th St & Teton Dr_2019.xlsm', 'S 70th St & Teton Dr_No Peds Apr 2019.xlsm', 'S 70th St & Van Dorn St No Peds_2019.xlsm', 'S 70th St & Wedgewood Dr_2017.xlsx', 'S 77th St & Old Cheney Rd_2016.xlsx', 'S 80th St & Pioneers Blvd_2019.xlsm', 'S 84th St & A St_2018.xlsx', 'S 84th St & Amber Hill Rd_2018.xlsm', 'S 84th St & Amber Hill Rd_2018.xlsx', 'S 84th St & Eiger Dr_2019.xlsm', 'S 84th St & Firethorn Ln Oct29_2019.xlsm', 'S 84th St & Firethorn Ln Oct30_2019.xlsm', 'S 84th St & Foxtail Dr_2022.xlsm', 'S 84th St & Glynoaks Dr-Augusta Dr_2016.xlsx', 'S 84th St & Glynoaks Dr-Augusta Dr_2017.xlsx', 'S 84th St & Glynoaks Dr-Augusta Dr_2018.xlsx', 'S 84th St & Old Cheney Rd_2018.xlsx', 'S 84th St & Pine Lake Rd_2017.xlsx', 'S 84th St & Pioneers Blvd_2019.xlsm', 'S 84th St & Rockledge Rd_2019.xlsm', 'S 84th St & S Cherrywood Dr_2019.xlsm', 'S 84th St & Sandalwood Dr_2019.xlsm', 'S 84th St & Van Dorn St_2018.xlsm', 'S 84th St & Yankee Woods Dr_2017.xlsx', 'S 87th St & Hwy 2_2019.xlsm', 'S 8th St & N St_2017.xlsx', 'S 8th St & N St_2018.xlsm', 'S 8th St & N St_September_Combined_NOTTEMPLATE.xlsx', 'S 9th St & A St_2018.xlsm', 'S 9th St & D St_2019.xlsm', 'S 9th St & F St Ped Oct_2017.xlsm', 'S 9th St & K St_2019.xlsm', 'S 9th St & L St_2019.xlsm', 'S 9th St & M St_2019.xlsm', 'S 9th St & N St_2019.xlsm', 'S 9th St & South St_2019.xlsm', 'S 9th St & Van Dorn St_2018.xlsm', 'S Antelope Valley & K St_2019.xlsm', 'S Antelope Valley Pkwy & L St_2019.xlsm', 'S Coddington Ave & W South St_2018.xlsm', 'S Cotner Blvd & Valley Rd_2017.xlsm', 'Sheridan Blvd & Van Dorn St Ped_2017.xlsm', 'Sheridan Blvd & Van Dorn St Ped_2019.xlsm', 'Skyway Rd-Cherrywood Dr & O St_2016.xlsx', 'Skyway Rd-Cherrywood Dr & O St_2019.xlsm', 'Southwood Dr & Hwy 2_2019.xlsm', 'Sun Valley Blvd & Charleston St_2020.xlsm', 'Sun Valley Blvd & Line Dr_2019.xlsm', 'SW 9th St & W A St_TMC_5Hr.xlsx', 'W Fletcher Ave & Hwy 34_2017.xlsx', 'W Fletcher Ave & Hwy 34_2017_US34madeNS.xlsx', 'W Fletcher Ave & Hwy 34_2020.xlsm', 'W South St & Folsom St West Intersection_2018 Folsom Major Street.xlsm', 'W South St & Folsom St West Intersection_2018 South Major Street.xlsm', 'W South St & Folsom St West Intersection_2018.xlsm', 'Warlick Blvd & Old Cheney Rd_2019.xlsm', 'Wedgewood Dr & O St_2019.xlsm', 'Wedgewood Dr & O St_2022.xlsm', 'Wilderness Ridge Dr & Yankee Hill Rd_2018.xlsm']\n",
      "(8684, 268)\n",
      "(2784, 268)\n"
     ]
    }
   ],
   "source": [
    "# This code cleans up the dbf \n",
    "\n",
    "# Filtering df1 to include only totals and the year 2021 counts\n",
    "df1_filtered = df1[(df1['Classification'] == 'Totals') & (df1['Year'] == 2021)]\n",
    "\n",
    "# Finding unique file names in df2 that are not in df1\n",
    "df1_filt_unq = df1_filtered['File_name'].drop_duplicates()\n",
    "df2_unq = df2['File_name'].drop_duplicates()\n",
    "unmatched_file_names = df2_unq[~df2_unq.isin(df1_filt_unq)].tolist()\n",
    "\n",
    "# Drop links with no intersection matches.\n",
    "df2_filtered = df2[~df2['File_name'].isin(unmatched_file_names)]\n",
    "\n",
    "print(unmatched_file_names)\n",
    "print(df2.shape)\n",
    "print(df2_filtered.shape)\n",
    "\n",
    "df2_filtered.to_csv('StL_filtered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e7f66e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msela\\AppData\\Local\\Temp\\ipykernel_17028\\3280910193.py:23: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df2_filtered[variable_names] = df2_filtered[variable_names].applymap(conv)\n",
      "C:\\Users\\msela\\AppData\\Local\\Temp\\ipykernel_17028\\3280910193.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2_filtered[variable_names] = df2_filtered[variable_names].applymap(conv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2784, 235)\n"
     ]
    }
   ],
   "source": [
    "# Joining receiving and approach ends for divided roadways in df2_filtered\n",
    "\n",
    "variable_names = [\n",
    "    'StL_0_0', 'StL_0_1', 'StL_0_2', 'StL_0_3', 'StL_0_4', 'StL_0_5', \n",
    "    'StL_1_0', 'StL_1_1', 'StL_1_2', 'StL_1_3', 'StL_1_4', 'StL_1_5', \n",
    "    'StL_2_0', 'StL_2_1', 'StL_2_2', 'StL_2_3', 'StL_2_4', 'StL_2_5', \n",
    "    'StL_3_0', 'StL_3_1', 'StL_3_2', 'StL_3_3', 'StL_3_4', 'StL_3_5', \n",
    "    'StL_4_0', 'StL_4_1', 'StL_4_2', 'StL_4_3', 'StL_4_4', 'StL_4_5', \n",
    "    'StL_5_0', 'StL_5_1', 'StL_5_2', 'StL_5_3', 'StL_5_4', 'StL_5_5', \n",
    "    'StL_6_0', 'StL_6_1', 'StL_6_2', 'StL_6_3', 'StL_6_4', 'StL_6_5', \n",
    "    'StL_7_0', 'StL_7_1', 'StL_7_2', 'StL_7_3', 'StL_7_4', 'StL_7_5'\n",
    "]\n",
    "\n",
    "\n",
    "# Custom conversion function to handle empty strings and extra precision\n",
    "def conv(value):\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return None  # indicating missing data\n",
    "\n",
    "# Converting columns to numeric, handling empty strings and extra precision\n",
    "df2_filtered[variable_names] = df2_filtered[variable_names].applymap(conv)\n",
    "\n",
    "# Grouping by file name and direction by summing StL indicators\n",
    "df2_grouped = df2_filtered.groupby(['File_name', 'Directio_1'])[variable_names].sum().reset_index()\n",
    "\n",
    "# Now adding columns 34-40 and columns 89-268\n",
    "merge_cols = ['File_name', 'Directio_1']\n",
    "# Select columns 34 to 40 \n",
    "cols_34_40 = df2_filtered.iloc[:, 33:40]\n",
    "# Select columns 89 to 268\n",
    "cols_89_268 = df2_filtered.iloc[:, 88:268]\n",
    "retained_cols = pd.concat([cols_34_40, cols_89_268], axis=1)\n",
    "\n",
    "df2_grouped = df2_grouped.merge(retained_cols, on = merge_cols, how='left')\n",
    "\n",
    "# Drop duplicate rows, keeping only the first occurrence\n",
    "#df2_grouped = df2_grouped.drop_duplicates(subset = merge_cols, keep='first')\n",
    "\n",
    "print(df2_grouped.shape)\n",
    "\n",
    "df2_grouped.to_csv('StL_filtered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0d10052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msela\\AppData\\Local\\Temp\\ipykernel_17028\\574343972.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1_filtered['Hour'] = df1_filtered['Start Time'].map(hour_dict)\n"
     ]
    }
   ],
   "source": [
    "# Now introducing the Hour variable into df1 to make grouping 15-minute counts easier\n",
    "\n",
    "# Creating a dictionary to map 'Start Time' to 'Hour'\n",
    "hour_dict = {\n",
    "    '12:00 AM': 1, '12:15 AM': 1, '12:30 AM': 1, '12:45 AM': 1,\n",
    "    '1:00 AM': 2, '1:15 AM': 2, '1:30 AM': 2, '1:45 AM': 2,\n",
    "    '2:00 AM': 3, '2:15 AM': 3, '2:30 AM': 3, '2:45 AM': 3,\n",
    "    '3:00 AM': 4, '3:15 AM': 4, '3:30 AM': 4, '3:45 AM': 4,\n",
    "    '4:00 AM': 5, '4:15 AM': 5, '4:30 AM': 5, '4:45 AM': 5,\n",
    "    '5:00 AM': 6, '5:15 AM': 6, '5:30 AM': 6, '5:45 AM': 6,\n",
    "    '6:00 AM': 7, '6:15 AM': 7, '6:30 AM': 7, '6:45 AM': 7,\n",
    "    '7:00 AM': 8, '7:15 AM': 8, '7:30 AM': 8, '7:45 AM': 8,\n",
    "    '8:00 AM': 9, '8:15 AM': 9, '8:30 AM': 9, '8:45 AM': 9,\n",
    "    '9:00 AM': 10, '9:15 AM': 10, '9:30 AM': 10, '9:45 AM': 10,\n",
    "    '10:00 AM': 11, '10:15 AM': 11, '10:30 AM': 11, '10:45 AM': 11,\n",
    "    '11:00 AM': 12, '11:15 AM': 12, '11:30 AM': 12, '11:45 AM': 12,\n",
    "    '12:00 PM': 13, '12:15 PM': 13, '12:30 PM': 13, '12:45 PM': 13,\n",
    "    '1:00 PM': 14, '1:15 PM': 14, '1:30 PM': 14, '1:45 PM': 14,\n",
    "    '2:00 PM': 15, '2:15 PM': 15, '2:30 PM': 15, '2:45 PM': 15,\n",
    "    '3:00 PM': 16, '3:15 PM': 16, '3:30 PM': 16, '3:45 PM': 16,\n",
    "    '4:00 PM': 17, '4:15 PM': 17, '4:30 PM': 17, '4:45 PM': 17,\n",
    "    '5:00 PM': 18, '5:15 PM': 18, '5:30 PM': 18, '5:45 PM': 18,\n",
    "    '6:00 PM': 19, '6:15 PM': 19, '6:30 PM': 19, '6:45 PM': 19,\n",
    "    '7:00 PM': 20, '7:15 PM': 20, '7:30 PM': 20, '7:45 PM': 20,\n",
    "    '8:00 PM': 21, '8:15 PM': 21, '8:30 PM': 21, '8:45 PM': 21,\n",
    "    '9:00 PM': 22, '9:15 PM': 22, '9:30 PM': 22, '9:45 PM': 22,\n",
    "    '10:00 PM': 23, '10:15 PM': 23, '10:30 PM': 23, '10:45 PM': 23,\n",
    "    '11:00 PM': 24, '11:15 PM': 24, '11:30 PM': 24, '11:45 PM': 24\n",
    "}\n",
    "\n",
    "df1_filtered['Hour'] = df1_filtered['Start Time'].map(hour_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f8f4bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now assigning count volumes to directions for easier integration with df2_grouped\n",
    "\n",
    "# Filter out rows where 'Approach' is not in the specified list\n",
    "valid_approaches = ['Eastbound', 'Westbound', 'Northbound', 'Southbound']\n",
    "df1_filtered = df1_filtered[df1_filtered['Approach'].isin(valid_approaches)]\n",
    "\n",
    "# Convert columns to numeric\n",
    "cols_convert = ['Right', 'Left', 'Thru', 'U-Turn']\n",
    "df1_filtered[cols_convert] = df1_filtered[cols_convert].apply(pd.to_numeric)\n",
    "\n",
    "def calc_direction (row):\n",
    "    if row['Approach'] == 'Eastbound':\n",
    "        W = row['Right'] + row['Left'] + row['Thru'] + 2*row['U-Turn']\n",
    "        E = row['Thru']\n",
    "        N = row['Left']\n",
    "        S = row['Right']\n",
    "    elif row['Approach'] == 'Westbound':\n",
    "        E = row['Right'] + row['Left'] + row['Thru'] + 2*row['U-Turn']\n",
    "        W = row['Thru']\n",
    "        S = row['Left']\n",
    "        N = row['Right']\n",
    "    elif row['Approach'] == 'Northbound':\n",
    "        S = row['Right'] + row['Left'] + row['Thru'] + 2*row['U-Turn']\n",
    "        N = row['Thru']\n",
    "        E = row['Right']\n",
    "        W = row['Left']\n",
    "    elif row['Approach'] == 'Southbound':\n",
    "        N = row['Right'] + row['Left'] + row['Thru'] + 2*row['U-Turn']\n",
    "        S = row['Thru']\n",
    "        W = row['Right']\n",
    "        E = row['Left']\n",
    "    return pd.Series([E, W, N, S])\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df1_filtered[['E', 'W', 'N', 'S']] = df1_filtered.apply(calc_direction, axis=1)\n",
    "\n",
    "df1_filtered.to_csv('counts_filtered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "388a57a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grouping counts by intersections (File_name) and hours\n",
    "\n",
    "df1_grouped = df1_filtered.groupby(['File_name', 'Hour'])[['E', 'W', 'N', 'S']].sum().reset_index()\n",
    "\n",
    "df1_grouped.to_csv('counts_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ada048b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           File_name Directio_1  StL_0_0  \\\n",
      "0                           14th St & O St_2021.xlsm          E  16092.2   \n",
      "1                           14th St & O St_2021.xlsm          N   1344.0   \n",
      "2                           14th St & O St_2021.xlsm          S   2872.6   \n",
      "3                           14th St & O St_2021.xlsm          W  16092.2   \n",
      "4                            1st St & O St_2021.xlsm          E  41796.4   \n",
      "...                                              ...        ...      ...   \n",
      "2779  Wilderness Ridge Dr & Yankee Hill Rd_2021.xlsm          N   2772.4   \n",
      "2780  Wilderness Ridge Dr & Yankee Hill Rd_2021.xlsm          N   2772.4   \n",
      "2781  Wilderness Ridge Dr & Yankee Hill Rd_2021.xlsm          N   2772.4   \n",
      "2782  Wilderness Ridge Dr & Yankee Hill Rd_2021.xlsm          W  18538.0   \n",
      "2783  Wilderness Ridge Dr & Yankee Hill Rd_2021.xlsm          W  18538.0   \n",
      "\n",
      "      StL_0_1  StL_0_2  StL_0_3  StL_0_4  StL_0_5  StL_1_0  StL_1_1  ...  \\\n",
      "0      2653.4   5038.6  10908.0  11430.4   8278.0  16092.2   1176.0  ...   \n",
      "1      2805.8   2805.8   2833.8   2833.8   2805.8   1236.4   2805.8  ...   \n",
      "2      2805.8   2833.8    775.8    710.0   2833.8   2153.2   2805.8  ...   \n",
      "3      2653.4   5121.6  13143.4  14290.6   9147.8  16656.2   1176.0  ...   \n",
      "4      1804.4   5848.4  14624.4  13242.4  13689.2  41336.0   1773.2  ...   \n",
      "...       ...      ...      ...      ...      ...      ...      ...  ...   \n",
      "2779    550.4    550.4    550.4    674.4    550.4   2772.4    550.4  ...   \n",
      "2780    550.4    550.4    550.4    674.4    550.4   2772.4    550.4  ...   \n",
      "2781    550.4    550.4    550.4    674.4    550.4   2772.4    550.4  ...   \n",
      "2782    275.2   2969.2   6097.2  15520.0   2999.2  19008.8    275.2  ...   \n",
      "2783    275.2   2969.2   6097.2  15520.0   2999.2  19008.8    275.2  ...   \n",
      "\n",
      "      Count_16  Count_17  Count_18  Count_19  Count_20  Count_21  Count_22  \\\n",
      "0       1554.0    1690.0    1584.0    1358.0    1169.0     976.0     801.0   \n",
      "1        176.0     194.0     202.0     198.0     176.0     120.0     100.0   \n",
      "2        143.0     160.0     163.0     123.0     115.0      84.0      82.0   \n",
      "3       1511.0    1638.0    1531.0    1293.0    1136.0     952.0     785.0   \n",
      "4       1632.0    1785.0    1618.0     613.0       NaN       NaN       NaN   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2779      48.0      58.0      85.0      25.0       NaN       NaN       NaN   \n",
      "2780      48.0      58.0      85.0      25.0       NaN       NaN       NaN   \n",
      "2781      48.0      58.0      85.0      25.0       NaN       NaN       NaN   \n",
      "2782     680.0     850.0    1068.0     393.0       NaN       NaN       NaN   \n",
      "2783     680.0     850.0    1068.0     393.0       NaN       NaN       NaN   \n",
      "\n",
      "      Count_23  Count_24  Day_of_Week  \n",
      "0        656.0     458.0     Thursday  \n",
      "1         79.0      70.0     Thursday  \n",
      "2         48.0      45.0     Thursday  \n",
      "3        635.0     445.0     Thursday  \n",
      "4          NaN       NaN      Tuesday  \n",
      "...        ...       ...          ...  \n",
      "2779       NaN       NaN      Tuesday  \n",
      "2780       NaN       NaN      Tuesday  \n",
      "2781       NaN       NaN      Tuesday  \n",
      "2782       NaN       NaN      Tuesday  \n",
      "2783       NaN       NaN      Tuesday  \n",
      "\n",
      "[2784 rows x 260 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create dataframe 2 with 24 Count columns initialized to NaN\n",
    "for hour in range(1, 25):\n",
    "    df2_grouped[f'Count_{hour}'] = np.nan\n",
    "\n",
    "# Iterate over rows in df2_grouped\n",
    "for index, row in df2_grouped.iterrows():\n",
    "    file_name = row['File_name']\n",
    "    direction = row['Directio_1']\n",
    "    \n",
    "    # Find corresponding row in df1_grouped\n",
    "    find_row = df1_grouped[df1_grouped['File_name'] == file_name]\n",
    "    \n",
    "    # Iterate over the 24 hours\n",
    "    for hour in range(1, 25):\n",
    "        # Extract value from df1 based on conditions\n",
    "        value = find_row.loc[find_row['Hour'] == hour, direction].values\n",
    "        if len(value) > 0:\n",
    "            df2_grouped.at[index, f'Count_{hour}'] = value[0]\n",
    "            \n",
    "# Now assigning Year, Month and Day_of_Week \n",
    "df1_DOW = df1_filtered[['File_name', 'Day_of_Week']].drop_duplicates(subset='File_name')\n",
    "# Merge df2_grouped with the unique entries from df1_grouped\n",
    "df2_grouped = df2_grouped.merge(df1_DOW, on='File_name', how='left')\n",
    "\n",
    "# Display resulting dataframe 2\n",
    "print(df2_grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bcd08b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now defining day parts (0 to 5) for counts according to StL day parts\n",
    "\n",
    "# Initializing Count_dp_{i} variables\n",
    "for i in [0, 1, 3, 4, 5]:\n",
    "    df2_grouped[f'Count_dp_{i}'] = np.nan\n",
    "    \n",
    "# Now assigning volumes to the Counts day parts based on their availabilities\n",
    "\n",
    "# This is for day part 0, which requires all hours to have counts\n",
    "df2_grouped['Count_dp_0'] = df2_grouped[[f'Count_{i}' for i in range(1, 25)]].apply(lambda row: row.sum() if row.notna().all() else np.nan, axis=1\n",
    ")\n",
    "\n",
    "# day part 1 (12AM to 6AM)\n",
    "df2_grouped['Count_dp_1'] = df2_grouped[[f'Count_{i}' for i in range(1, 7)]].apply(lambda row: row.sum() if row.notna().all() else np.nan, axis=1\n",
    ")\n",
    "\n",
    "# day part 2 (6AM to 10AM)\n",
    "df2_grouped['Count_dp_2'] = df2_grouped[[f'Count_{i}' for i in range(7, 11)]].apply(lambda row: row.sum() if row.notna().all() else np.nan, axis=1\n",
    ")\n",
    "\n",
    "# day part 3 (10AM to 3PM)\n",
    "df2_grouped['Count_dp_3'] = df2_grouped[[f'Count_{i}' for i in range(11, 16)]].apply(lambda row: row.sum() if row.notna().all() else np.nan, axis=1\n",
    ")\n",
    "\n",
    "# day part 4 (3PM to 7PM)\n",
    "df2_grouped['Count_dp_4'] = df2_grouped[[f'Count_{i}' for i in range(16, 20)]].apply(lambda row: row.sum() if row.notna().all() else np.nan, axis=1\n",
    ")\n",
    "\n",
    "# day part 5 (7PM to 12AM)\n",
    "df2_grouped['Count_dp_5'] = df2_grouped[[f'Count_{i}' for i in range(20, 25)]].apply(lambda row: row.sum() if row.notna().all() else np.nan, axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fbeb7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalizing the StL variable and the counts dependent variable for each row.\n",
    "\n",
    "# Count variable\n",
    "def calculate_count_vol(x):\n",
    "    if pd.notna(x['Count_dp_0']):\n",
    "        return x['Count_dp_0']\n",
    "    else:\n",
    "        return x[['Count_dp_1', 'Count_dp_2', 'Count_dp_3', 'Count_dp_4', 'Count_dp_5']].sum(skipna=True)\n",
    "\n",
    "df2_grouped['Count_vol'] = df2_grouped.apply(calculate_count_vol, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cfd90df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now calculating the StL volume that corresponds to the available counts\n",
    "\n",
    "# Dictionary to map day of week to the number in the StL variables\n",
    "day_mapping = {\n",
    "    'Monday': 1,\n",
    "    'Tuesday': 2,\n",
    "    'Wednesday': 3,\n",
    "    'Thursday': 4,\n",
    "    'Friday': 5,\n",
    "    'Saturday': 6,\n",
    "    'Sunday': 7\n",
    "}\n",
    "\n",
    "# Define a function to calculate StL_x, which is the explanatory StL variable in the model\n",
    "def calculate_StL_x(row):\n",
    "    day_num = day_mapping[row['Day_of_Week']]\n",
    "    if pd.notna(row['Count_dp_0']):\n",
    "        return row[f'StL_{day_num}_0']  # returns all day StL for the corresponding day if 24 counts are available\n",
    "    else:\n",
    "        counts = row[['Count_dp_1', 'Count_dp_2', 'Count_dp_3', 'Count_dp_4', 'Count_dp_5']]\n",
    "        # Select the corresponding StL columns\n",
    "        stl_cols = [f'StL_{day_num}_{i}' for i in range(1, 6)]\n",
    "        stl_values = row[stl_cols]\n",
    "        # Sum the non-NaN values for the StL values corresponding the same day for day parts 1 to 5\n",
    "        valid_stl_values = stl_values[counts.notna().values]\n",
    "        return valid_stl_values.sum()\n",
    "\n",
    "# Apply the function to each row to create the 'StL_x' column\n",
    "df2_grouped['StL_x'] = df2_grouped.apply(calculate_StL_x, axis=1)\n",
    "\n",
    "df2_grouped.to_csv('vcalibration_input.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
